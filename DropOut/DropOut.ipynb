{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOpZHJ5sYGgd",
        "outputId": "7b22ea9e-78d4-42fc-ce24-94e5ff6d0551"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 2s 0us/step\n",
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 46s 27ms/step - loss: 1.8462 - accuracy: 0.3334 - val_loss: 1.7531 - val_accuracy: 0.3696\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 1.6558 - accuracy: 0.4089 - val_loss: 1.6241 - val_accuracy: 0.4076\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 1.5856 - accuracy: 0.4320 - val_loss: 1.5536 - val_accuracy: 0.4468\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 1.5359 - accuracy: 0.4503 - val_loss: 1.5067 - val_accuracy: 0.4580\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 1.5010 - accuracy: 0.4626 - val_loss: 1.5402 - val_accuracy: 0.4506\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 1.4751 - accuracy: 0.4737 - val_loss: 1.5129 - val_accuracy: 0.4550\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 1.4500 - accuracy: 0.4827 - val_loss: 1.5293 - val_accuracy: 0.4544\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 1.4297 - accuracy: 0.4892 - val_loss: 1.5270 - val_accuracy: 0.4588\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 1.4113 - accuracy: 0.4971 - val_loss: 1.4785 - val_accuracy: 0.4744\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 1.3931 - accuracy: 0.5019 - val_loss: 1.4908 - val_accuracy: 0.4753\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 1.4908 - accuracy: 0.4753\n",
            "Test accuracy: 0.47530001401901245\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# CIFAR10 데이터셋 로드\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# 데이터 전처리\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# 모델 생성\n",
        "model = models.Sequential([\n",
        "    layers.Flatten(input_shape=(32, 32, 3)),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 모델 훈련\n",
        "history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))\n",
        "\n",
        "# 모델 평가\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIpBqs20ZUsX",
        "outputId": "2ca4389a-d82b-4f22-cf36-283bbbd4d153"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 40s 25ms/step - loss: 1.9841 - accuracy: 0.2685 - val_loss: 1.8295 - val_accuracy: 0.3424\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 1.8675 - accuracy: 0.3163 - val_loss: 1.7480 - val_accuracy: 0.3682\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 1.8196 - accuracy: 0.3330 - val_loss: 1.7122 - val_accuracy: 0.3852\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 1.7917 - accuracy: 0.3442 - val_loss: 1.7866 - val_accuracy: 0.3552\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 1.7729 - accuracy: 0.3528 - val_loss: 1.7047 - val_accuracy: 0.3835\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 1.7525 - accuracy: 0.3622 - val_loss: 1.6827 - val_accuracy: 0.4002\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 1.7383 - accuracy: 0.3687 - val_loss: 1.6624 - val_accuracy: 0.3969\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 1.7284 - accuracy: 0.3737 - val_loss: 1.6605 - val_accuracy: 0.4048\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 1.7127 - accuracy: 0.3773 - val_loss: 1.6450 - val_accuracy: 0.4171\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 1.7014 - accuracy: 0.3836 - val_loss: 1.6551 - val_accuracy: 0.4067\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 1.6551 - accuracy: 0.4067\n",
            "Test accuracy with Dropout: 0.4066999852657318\n"
          ]
        }
      ],
      "source": [
        "# Dropout 층 추가\n",
        "model_with_dropout = models.Sequential([\n",
        "    layers.Flatten(input_shape=(32, 32, 3)),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dropout(0.2),  # Dropout 추가\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.2),  # Dropout 추가\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model_with_dropout.compile(optimizer='adam',\n",
        "                            loss='categorical_crossentropy',\n",
        "                            metrics=['accuracy'])\n",
        "\n",
        "# 모델 훈련\n",
        "history = model_with_dropout.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))\n",
        "\n",
        "# 모델 평가\n",
        "test_loss, test_acc = model_with_dropout.evaluate(x_test, y_test)\n",
        "print('Test accuracy with Dropout:', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzQvn8yDby2B",
        "outputId": "b15e0a2d-bc88-4ddb-8a92-882aadaf3d32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 39s 24ms/step - loss: 1.8549 - accuracy: 0.3317 - val_loss: 1.7335 - val_accuracy: 0.3756\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 1.6706 - accuracy: 0.4007 - val_loss: 1.6605 - val_accuracy: 0.4118\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 1.5920 - accuracy: 0.4312 - val_loss: 1.5410 - val_accuracy: 0.4523\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 38s 25ms/step - loss: 1.5392 - accuracy: 0.4502 - val_loss: 1.5279 - val_accuracy: 0.4591\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 1.4983 - accuracy: 0.4642 - val_loss: 1.4976 - val_accuracy: 0.4622\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 38s 25ms/step - loss: 1.4722 - accuracy: 0.4740 - val_loss: 1.4932 - val_accuracy: 0.4716\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 1.4441 - accuracy: 0.4835 - val_loss: 1.5160 - val_accuracy: 0.4574\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 1.4256 - accuracy: 0.4912 - val_loss: 1.5156 - val_accuracy: 0.4734\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 1.3980 - accuracy: 0.5012 - val_loss: 1.4407 - val_accuracy: 0.4879\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 1.3806 - accuracy: 0.5086 - val_loss: 1.4515 - val_accuracy: 0.4828\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 1.4515 - accuracy: 0.4828\n",
            "Test accuracy without Dropout: 0.4828000068664551\n",
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 40s 25ms/step - loss: 1.9928 - accuracy: 0.2686 - val_loss: 1.8204 - val_accuracy: 0.3573\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 1.8696 - accuracy: 0.3156 - val_loss: 1.7948 - val_accuracy: 0.3461\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 1.8183 - accuracy: 0.3386 - val_loss: 1.7531 - val_accuracy: 0.3704\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 1.7911 - accuracy: 0.3552 - val_loss: 1.6872 - val_accuracy: 0.3993\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 1.7745 - accuracy: 0.3589 - val_loss: 1.6894 - val_accuracy: 0.3989\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 1.7547 - accuracy: 0.3619 - val_loss: 1.6684 - val_accuracy: 0.4054\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 1.7399 - accuracy: 0.3685 - val_loss: 1.6410 - val_accuracy: 0.4195\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 1.7261 - accuracy: 0.3764 - val_loss: 1.6676 - val_accuracy: 0.4057\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 1.7203 - accuracy: 0.3807 - val_loss: 1.6666 - val_accuracy: 0.4094\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 1.7087 - accuracy: 0.3819 - val_loss: 1.6410 - val_accuracy: 0.4192\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 1.6410 - accuracy: 0.4192\n",
            "Test accuracy with Dropout: 0.41920000314712524\n",
            "Overfitting comparison:\n",
            "Test accuracy without Dropout: 0.4828000068664551\n",
            "Test accuracy with Dropout: 0.41920000314712524\n"
          ]
        }
      ],
      "source": [
        "# 모델 생성 - Dropout 층 없는 경우\n",
        "model_no_dropout = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(32, 32, 3)),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model_no_dropout.compile(optimizer='adam',\n",
        "                          loss='categorical_crossentropy',\n",
        "                          metrics=['accuracy'])\n",
        "\n",
        "# 모델 훈련\n",
        "history_no_dropout = model_no_dropout.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))\n",
        "\n",
        "# 모델 평가 - Dropout 층 없는 경우\n",
        "test_loss_no_dropout, test_acc_no_dropout = model_no_dropout.evaluate(x_test, y_test)\n",
        "print('Test accuracy without Dropout:', test_acc_no_dropout)\n",
        "\n",
        "# Dropout 층 추가\n",
        "model_with_dropout = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(32, 32, 3)),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),  # Dropout 추가\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),  # Dropout 추가\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model_with_dropout.compile(optimizer='adam',\n",
        "                            loss='categorical_crossentropy',\n",
        "                            metrics=['accuracy'])\n",
        "\n",
        "# 모델 훈련\n",
        "history_with_dropout = model_with_dropout.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))\n",
        "\n",
        "# 모델 평가 - Dropout 층 있는 경우\n",
        "test_loss_with_dropout, test_acc_with_dropout = model_with_dropout.evaluate(x_test, y_test)\n",
        "print('Test accuracy with Dropout:', test_acc_with_dropout)\n",
        "\n",
        "# 과대적합 비교\n",
        "print('Overfitting comparison:')\n",
        "print('Test accuracy without Dropout:', test_acc_no_dropout)\n",
        "print('Test accuracy with Dropout:', test_acc_with_dropout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cBu1wP1gKV6",
        "outputId": "ef9e5f19-2910-424d-ac54-bdd021b7fd59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 2s 5ms/step\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "313/313 [==============================] - 2s 7ms/step\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "313/313 [==============================] - 2s 6ms/step\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "313/313 [==============================] - 2s 8ms/step\n",
            "313/313 [==============================] - 2s 6ms/step\n",
            "313/313 [==============================] - 2s 6ms/step\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "313/313 [==============================] - 2s 6ms/step\n",
            "313/313 [==============================] - 2s 7ms/step\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "313/313 [==============================] - 2s 8ms/step\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "313/313 [==============================] - 2s 6ms/step\n",
            "313/313 [==============================] - 2s 7ms/step\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "313/313 [==============================] - 2s 8ms/step\n",
            "313/313 [==============================] - 2s 6ms/step\n",
            "313/313 [==============================] - 2s 7ms/step\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "313/313 [==============================] - 2s 6ms/step\n",
            "313/313 [==============================] - 2s 6ms/step\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "313/313 [==============================] - 2s 6ms/step\n",
            "313/313 [==============================] - 2s 6ms/step\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "313/313 [==============================] - 2s 6ms/step\n",
            "313/313 [==============================] - 2s 6ms/step\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "313/313 [==============================] - 2s 6ms/step\n",
            "313/313 [==============================] - 2s 6ms/step\n",
            "Confusion Matrix:\n",
            "[[460  41  39  62  19   6  45  28 177 123]\n",
            " [ 35 450   2  46   9  11  33  23 100 291]\n",
            " [109  27 159 135 162  57 219  58  31  43]\n",
            " [ 32  14  51 331  40 132 238  42  33  87]\n",
            " [ 58   9  90 111 331  33 232  65  28  43]\n",
            " [ 17  12  52 254  70 278 184  47  38  48]\n",
            " [  8  11  30 117 113  28 624  19   8  42]\n",
            " [ 27  23  42  93 105  64 121 378  18 129]\n",
            " [119  56   5  62   5   9  17  13 553 161]\n",
            " [ 22 123   1  53   3  10  37  32  91 628]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# 몬테카를로 시뮬레이션 횟수 설정\n",
        "num_monte_carlo = 50\n",
        "\n",
        "# 각 클래스별 몬테카를로 예측을 저장할 리스트 초기화\n",
        "monte_carlo_predictions = [[] for _ in range(len(y_test))]\n",
        "\n",
        "# 몬테카를로 시뮬레이션 실행\n",
        "for _ in range(num_monte_carlo):\n",
        "    predictions = model_with_dropout.predict(x_test)  # 드롭아웃 적용 모델로 예측\n",
        "    for i, pred in enumerate(predictions):\n",
        "        monte_carlo_predictions[i].append(np.argmax(pred))  # 가장 높은 확률을 갖는 클래스를 저장\n",
        "\n",
        "# 각 데이터 포인트에 대한 몬테카를로 예측의 평균을 계산\n",
        "monte_carlo_averaged_predictions = [np.argmax(np.bincount(preds)) for preds in monte_carlo_predictions]\n",
        "\n",
        "# 혼동 행렬 계산\n",
        "conf_matrix = confusion_matrix(np.argmax(y_test, axis=1), monte_carlo_averaged_predictions)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUhbO8tMlY9r"
      },
      "source": [
        "주로 대각선에 있는 값들이 높고 비대각선 값들이 낮을 수록 모델의 성능이 좋다. 위의 행렬은 대각선 요소가 높고, 주요 오분류 패턴이 나타나지 않으므로 괜찮은 성능을 가지고 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4I1Q-0gZ1oHd"
      },
      "source": [
        "Adam 기법을 사용했습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqOygs5FjhsZ",
        "outputId": "23297415-dbbd-4ff3-8017-a06ac06666a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "782/782 [==============================] - 25s 31ms/step - loss: 1.8746 - accuracy: 0.3274 - val_loss: 1.7268 - val_accuracy: 0.3828\n",
            "Epoch 2/15\n",
            "782/782 [==============================] - 23s 29ms/step - loss: 1.6716 - accuracy: 0.3985 - val_loss: 1.6120 - val_accuracy: 0.4212\n",
            "Epoch 3/15\n",
            "782/782 [==============================] - 23s 30ms/step - loss: 1.5820 - accuracy: 0.4361 - val_loss: 1.5507 - val_accuracy: 0.4493\n",
            "Epoch 4/15\n",
            "782/782 [==============================] - 22s 28ms/step - loss: 1.5292 - accuracy: 0.4515 - val_loss: 1.5398 - val_accuracy: 0.4598\n",
            "Epoch 5/15\n",
            "782/782 [==============================] - 23s 29ms/step - loss: 1.4881 - accuracy: 0.4724 - val_loss: 1.5134 - val_accuracy: 0.4636\n",
            "Epoch 6/15\n",
            "782/782 [==============================] - 23s 29ms/step - loss: 1.4524 - accuracy: 0.4812 - val_loss: 1.4694 - val_accuracy: 0.4743\n",
            "Epoch 7/15\n",
            "782/782 [==============================] - 22s 29ms/step - loss: 1.4217 - accuracy: 0.4910 - val_loss: 1.4651 - val_accuracy: 0.4810\n",
            "Epoch 8/15\n",
            "782/782 [==============================] - 22s 28ms/step - loss: 1.4055 - accuracy: 0.4975 - val_loss: 1.4527 - val_accuracy: 0.4855\n",
            "Epoch 9/15\n",
            "782/782 [==============================] - 23s 30ms/step - loss: 1.3793 - accuracy: 0.5086 - val_loss: 1.4386 - val_accuracy: 0.4823\n",
            "Epoch 10/15\n",
            "782/782 [==============================] - 23s 29ms/step - loss: 1.3519 - accuracy: 0.5177 - val_loss: 1.4482 - val_accuracy: 0.4838\n",
            "Epoch 11/15\n",
            "782/782 [==============================] - 23s 30ms/step - loss: 1.3378 - accuracy: 0.5232 - val_loss: 1.4283 - val_accuracy: 0.4969\n",
            "Epoch 12/15\n",
            "782/782 [==============================] - 23s 29ms/step - loss: 1.3156 - accuracy: 0.5296 - val_loss: 1.4298 - val_accuracy: 0.4927\n",
            "Epoch 13/15\n",
            "782/782 [==============================] - 24s 30ms/step - loss: 1.3001 - accuracy: 0.5350 - val_loss: 1.4462 - val_accuracy: 0.4818\n",
            "Epoch 14/15\n",
            "782/782 [==============================] - 23s 29ms/step - loss: 1.2869 - accuracy: 0.5418 - val_loss: 1.3957 - val_accuracy: 0.5021\n",
            "Epoch 15/15\n",
            "782/782 [==============================] - 22s 28ms/step - loss: 1.2647 - accuracy: 0.5487 - val_loss: 1.3939 - val_accuracy: 0.5080\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 1.3939 - accuracy: 0.5080\n",
            "Test accuracy: 0.5080000162124634\n"
          ]
        }
      ],
      "source": [
        "# 모델 생성\n",
        "model = models.Sequential([\n",
        "    layers.Flatten(input_shape=(32, 32, 3)),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)  # Adam 옵티마이저, 학습률을 0.001로 설정\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 모델 훈련\n",
        "history = model.fit(x_train, y_train, epochs=15, batch_size=64, validation_data=(x_test, y_test))  # 에포크를 15로 변경, 배치 크기를 64로 변경\n",
        "\n",
        "# 모델 평가\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6BLSpmf1txH"
      },
      "source": [
        "기존 다층 퍼셉트론의 정확도 : Test accuracy: 0.47530001401901245\n",
        "\n",
        "Adam 기법으로 변형했을 때의 정확도 : Test accuracy: 0.5080000162124634"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
